# Презентация: Интеллектуальный цифровой инженер данных (ИЦИД)

## Слайд 1. Титульный
- Название: Интеллектуальный цифровой инженер данных (ИЦИД)
- 1‑лайнер: «Data Engineering без собственного веб‑UI — через IDE Cursor»
- Иллюстрация (ASCII‑диаграмма):

```
+------------------+      +---------------------+      +------------------+
|   Источники      | ---> |  Трансформации/ETL  | ---> |   Артефакты      |
| CSV/JSON/XML/ZIP |      |  (Python в Docker)  |      | CSV/Parquet/DB   |
+------------------+      +---------------------+      +------------------+
```

## Слайд 2. Проблема
- Настройка DE‑стека и пайплайнов требует много времени и разрозненных UI.
- Сложно держать единый контекст: анализ → проектирование → выполнение → отчёт.
- Для демо/PoC команды тратят непропорционально много усилий на инфраструктуру.

## Слайд 3. Подход
- IDE‑первый опыт: диалог и управление из Cursor (чат, терминал, Tasks).
- «Правила как продукт»: стандартизированные правила для диаграмм, отчётов, кодогенерации.
- Минимум инфраструктуры: Docker, cron, локальные артефакты.

## Слайд 4. Архитектура без веб‑UI
- Cursor (чат/Tasks) ↔ `.cursor/rules/` ↔ контейнер (раннер/скрипты) ↔ файловые артефакты.
- Компоненты: Python‑раннер, утилиты `pandas/pyarrow`, `Makefile`, cron.
- Хранилище: CSV/Parquet/SQLite (в контейнере/томе).

## Слайд 5. Диалог и ASCII‑пайплайн
- Шаги: запрос в чат → обновлённая ASCII‑диаграмма → сгенерированный план.
- Диаграмма обновляется при каждом взаимодействии.
- Формируется единый план выполнения и конфигурации (`pipeline.yaml`).

## Слайд 6. Трансформации
- Библиотека шагов: filter, aggregate, join.
- Рекомендации по целевому формату (CSV/Parquet/SQLite).
- Генерация кода: парсеры, трансформации, конфиги.

## Слайд 7. Запуск и расписание
- Команда: `make run` или `python run_pipeline.py --config pipeline.yaml`.
- Расписание: cron в контейнере, маска из `.env`.
- Пример: `CRON_SCHEDULE="0 * * * *"`.

## Слайд 8. Отчётность
- Авто‑отчёт `reports/run-YYYYMMDD.md`.
- Содержимое: параметры запуска, длительности, размеры данных, перечень шагов и причины решений.
- Логи и артефакты доступны локально.

## Слайд 9. Тестовые данные
- Используются локальные CSV/JSON/XML (в том числе ZIP) для быстрых демонстраций.
- Мини‑таблица характеристик датасетов (см. анализ в репозитории).
- Фокус: повторяемость демо и скорость воспроизведения.

## Слайд 10. Развёртывание
- 3 команды:
  1) `docker compose up`
  2) `make init`
  3) `make run`
- Никаких внешних БД в MVP; всё локально и воспроизводимо.

## Слайд 11. Безопасность
- Секреты: только `.env` (в репо — `.env.example`).
- Нет реальных ключей в репозитории; локальные тома.
- Минимум периметра в демо‑режиме.

## Слайд 12. Roadmap (Next)
- Внешние БД: PostgreSQL/ClickHouse/HDFS.
- Оркестрация: Airflow/Prefect/Dagster/Flyte.
- Стриминг: Kafka.
- Трансформации: dbt + DWH.
- Платформа: k8s, расширенный мониторинг/алёртинг, секреты (Vault/KMS).

## Приложение. Позиционирование и конкурентный анализ
- См. `documents/solution/application.md`: 14‑критериальная таблица и краткие описания (Airflow, Prefect, Dagster, Kedro, Flyte, dbt, Meltano, Airbyte, AWS Glue, Azure Data Factory, GCP Data Fusion).


